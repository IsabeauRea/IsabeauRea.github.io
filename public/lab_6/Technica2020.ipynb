{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.0 64-bit",
   "display_name": "Python 3.8.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import helper\n",
    "from glob import glob\n",
    "import pickle as pkl\n",
    "import scipy.misc\n",
    "\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "do_preprocess = False\n",
    "from_checkpoint = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Claude_Monet'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c7e0147e95ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Claude_Monet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-c7e0147e95ef>\u001b[0m in \u001b[0;36mload_images_from_folder\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Claude_Monet'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "load_images_from_folder(\"Claude_Monet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, BatchNormalization, Input, GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "# function for building the discriminator layers\n",
    "def build_discriminator(start_filters, spatial_dim, filter_size):\n",
    "    \n",
    "    # function for building a CNN block for downsampling the image\n",
    "    def add_discriminator_block(x, filters, filter_size):\n",
    "      x = Conv2D(filters, filter_size, padding='same')(x)\n",
    "      x = BatchNormalization()(x)\n",
    "      x = Conv2D(filters, filter_size, padding='same', strides=2)(x)\n",
    "      x = BatchNormalization()(x)\n",
    "      x = LeakyReLU(0.3)(x)\n",
    "      return x\n",
    "    \n",
    "    # input is an image with shape spatial_dim x spatial_dim and 3 channels\n",
    "    inp = Input(shape=(spatial_dim, spatial_dim, 3))\n",
    "\n",
    "    # design the discrimitor to downsample the image 4x\n",
    "    x = add_discriminator_block(inp, start_filters, filter_size)\n",
    "    x = add_discriminator_block(x, start_filters * 2, filter_size)\n",
    "    x = add_discriminator_block(x, start_filters * 4, filter_size)\n",
    "    x = add_discriminator_block(x, start_filters * 8, filter_size)\n",
    "    \n",
    "    # average and return a binary output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Deconvolution2D, Reshape\n",
    "\n",
    "def build_generator(start_filters, filter_size, latent_dim):\n",
    "  \n",
    "  # function for building a CNN block for upsampling the image\n",
    "  def add_generator_block(x, filters, filter_size):\n",
    "      x = Deconvolution2D(filters, filter_size, strides=2, padding='same')(x)\n",
    "      x = BatchNormalization()(x)\n",
    "      x = LeakyReLU(0.3)(x)\n",
    "      return x\n",
    "\n",
    "  # input is a noise vector \n",
    "  inp = Input(shape=(latent_dim,))\n",
    "\n",
    "  # projection of the noise vector into a tensor with \n",
    "  # same shape as last conv layer in discriminator\n",
    "  x = Dense(4 * 4 * (start_filters * 8), input_dim=latent_dim)(inp)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Reshape(target_shape=(4, 4, start_filters * 8))(x)\n",
    "\n",
    "  # design the generator to upsample the image 4x\n",
    "  x = add_generator_block(x, start_filters * 4, filter_size)\n",
    "  x = add_generator_block(x, start_filters * 2, filter_size)\n",
    "  x = add_generator_block(x, start_filters, filter_size)\n",
    "  x = add_generator_block(x, start_filters, filter_size)    \n",
    "\n",
    "  # turn the output into a 3D tensor, an image with 3 channels \n",
    "  x = Conv2D(3, kernel_size=5, padding='same', activation='tanh')(x)\n",
    "  \n",
    "  return Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(image_files, width, height, mode):\n",
    "    data_batch = np.array(\n",
    "        [get_image(sample_file, width, height, mode) for sample_file in image_files]).astype(np.float32)\n",
    "\n",
    "    # Make sure the images are in 4 dimensions\n",
    "    if len(data_batch.shape) < 4:\n",
    "        data_batch = data_batch.reshape(data_batch.shape + (1,))\n",
    "\n",
    "    return data_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "./artdata\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = \n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./artdata\" # Data\n",
    "data_resized_dir = \"./resized_data\"# Resized data\n",
    "\n",
    "if do_preprocess == True:\n",
    "    os.mkdir(data_resized_dir)\n",
    "\n",
    "    for each in os.listdir(data_dir):\n",
    "        image = cv2.imread(os.path.join(data_dir, each))\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        cv2.imwrite(os.path.join(data_resized_dir, each), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part was taken from Udacity Face generator project\n",
    "def get_image(image_path, width, height, mode):\n",
    "    \"\"\"\n",
    "    Read image from image_path\n",
    "    :param image_path: Path of image\n",
    "    :param width: Width of image\n",
    "    :param height: Height of image\n",
    "    :param mode: Mode of image\n",
    "    :return: Image data\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    return np.array(image.convert(mode))\n",
    "\n",
    "def get_batch(image_files, width, height, mode):\n",
    "    data_batch = np.array(\n",
    "        [get_image(sample_file, width, height, mode) for sample_file in image_files]).astype(np.float32)\n",
    "\n",
    "    # Make sure the images are in 4 dimensions\n",
    "    if len(data_batch.shape) < 4:\n",
    "        data_batch = data_batch.reshape(data_batch.shape + (1,))\n",
    "\n",
    "    return data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'helper' has no attribute 'get_batch'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5a3c5c6e0bdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mshow_n_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmnist_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_resized_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mshow_n_images\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages_square_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'helper' has no attribute 'get_batch'"
     ]
    }
   ],
   "source": [
    "show_n_images = 25\n",
    "mnist_images = helper.get_batch(glob(os.path.join(data_resized_dir, '*.jpg'))[:show_n_images], 64, 64, 'RGB')\n",
    "plt.imshow(helper.images_square_grid(mnist_images, 'RGB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, output_channel_dim, is_train=True):\n",
    "    ''' Build the generator network.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        z : Input tensor for the generator\n",
    "        output_channel_dim : Shape of the generator output\n",
    "        n_units : Number of units in hidden layer\n",
    "        reuse : Reuse the variables with tf.variable_scope\n",
    "        alpha : leak parameter for leaky ReLU\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out: \n",
    "    '''\n",
    "    with tf.variable_scope(\"generator\", reuse= not is_train):\n",
    "        \n",
    "        # First FC layer --> 8x8x1024\n",
    "        fc1 = tf.layers.dense(z, 8*8*1024)\n",
    "        \n",
    "        # Reshape it\n",
    "        fc1 = tf.reshape(fc1, (-1, 8, 8, 1024))\n",
    "        \n",
    "        # Leaky ReLU\n",
    "        fc1 = tf.nn.leaky_relu(fc1, alpha=alpha)\n",
    "\n",
    "        \n",
    "        # Transposed conv 1 --> BatchNorm --> LeakyReLU\n",
    "        # 8x8x1024 --> 16x16x512\n",
    "        trans_conv1 = tf.layers.conv2d_transpose(inputs = fc1,\n",
    "                                  filters = 512,\n",
    "                                  kernel_size = [5,5],\n",
    "                                  strides = [2,2],\n",
    "                                  padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name=\"trans_conv1\")\n",
    "        \n",
    "        batch_trans_conv1 = tf.layers.batch_normalization(inputs = trans_conv1, training=is_train, epsilon=1e-5, name=\"batch_trans_conv1\")\n",
    "       \n",
    "        trans_conv1_out = tf.nn.leaky_relu(batch_trans_conv1, alpha=alpha, name=\"trans_conv1_out\")\n",
    "        \n",
    "        \n",
    "        # Transposed conv 2 --> BatchNorm --> LeakyReLU\n",
    "        # 16x16x512 --> 32x32x256\n",
    "        trans_conv2 = tf.layers.conv2d_transpose(inputs = trans_conv1_out,\n",
    "                                  filters = 256,\n",
    "                                  kernel_size = [5,5],\n",
    "                                  strides = [2,2],\n",
    "                                  padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name=\"trans_conv2\")\n",
    "        \n",
    "        batch_trans_conv2 = tf.layers.batch_normalization(inputs = trans_conv2, training=is_train, epsilon=1e-5, name=\"batch_trans_conv2\")\n",
    "       \n",
    "        trans_conv2_out = tf.nn.leaky_relu(batch_trans_conv2, alpha=alpha, name=\"trans_conv2_out\")\n",
    "        \n",
    "        \n",
    "        # Transposed conv 3 --> BatchNorm --> LeakyReLU\n",
    "        # 32x32x256 --> 64x64x128\n",
    "        trans_conv3 = tf.layers.conv2d_transpose(inputs = trans_conv2_out,\n",
    "                                  filters = 128,\n",
    "                                  kernel_size = [5,5],\n",
    "                                  strides = [2,2],\n",
    "                                  padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name=\"trans_conv3\")\n",
    "        \n",
    "        batch_trans_conv3 = tf.layers.batch_normalization(inputs = trans_conv3, training=is_train, epsilon=1e-5, name=\"batch_trans_conv3\")\n",
    "       \n",
    "        trans_conv3_out = tf.nn.leaky_relu(batch_trans_conv3, alpha=alpha, name=\"trans_conv3_out\")\n",
    "\n",
    "        \n",
    "        # Transposed conv 4 --> BatchNorm --> LeakyReLU\n",
    "        # 64x64x128 --> 128x128x64\n",
    "        trans_conv4 = tf.layers.conv2d_transpose(inputs = trans_conv3_out,\n",
    "                                  filters = 64,\n",
    "                                  kernel_size = [5,5],\n",
    "                                  strides = [2,2],\n",
    "                                  padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name=\"trans_conv4\")\n",
    "        \n",
    "        batch_trans_conv4 = tf.layers.batch_normalization(inputs = trans_conv4, training=is_train, epsilon=1e-5, name=\"batch_trans_conv4\")\n",
    "       \n",
    "        trans_conv4_out = tf.nn.leaky_relu(batch_trans_conv4, alpha=alpha, name=\"trans_conv4_out\")\n",
    "\n",
    "        \n",
    "        # Transposed conv 5 --> tanh\n",
    "        # 128x128x64 --> 128x128x3\n",
    "        logits = tf.layers.conv2d_transpose(inputs = trans_conv4_out,\n",
    "                                  filters = 3,\n",
    "                                  kernel_size = [5,5],\n",
    "                                  strides = [1,1],\n",
    "                                  padding = \"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                name=\"logits\")\n",
    "         \n",
    "        out = tf.tanh(logits, name=\"out\")\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}